{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm, Minimum Spanning Tree, and Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - internet routing\n",
    "\n",
    "- ex. Stanford gateway router needs to send data to the Cornell gateway router\n",
    "- Djikstra's algorithm does this (with nonnegative edge length)\n",
    "- issue is that Stanford gateway router would need to know entire Internet\n",
    "- need a shortest-path algorithm that uses only local computation\n",
    "- solution is Bellman-Ford algorithm (also handles negative edge costs)\n",
    "\n",
    "## Application - sequence alignment\n",
    "\n",
    "- input: two strings over the alphabet {A,C,G,T}\n",
    "- problem: figure out how similar the two strings are\n",
    "- measure similarity via quality of \"best\" alignment\n",
    "    - penalty $pen_{gap} \\ge 0$ for each gap\n",
    "    - penalty $pen_{AT} \\ge 0$ for mismatching A and T\n",
    "    - etc\n",
    "- output: alignment of the strings that minimizes the total penalty (Needleman-Wunsch score)\n",
    "- solution: straightforward dynamic programming\n",
    "\n",
    "## Greedy algorithm\n",
    "\n",
    "- ex. Dijkstra's shortest path algorithm\n",
    "- easy to propose\n",
    "- easy runtime analysis\n",
    "- hard to eatablish correctness\n",
    "- most greedy algorithms are not correct\n",
    "\n",
    "## Application - optimal caching\n",
    "\n",
    "- cache is faster than memory\n",
    "- on a fault (cache miss), need to evict something from cache to make room\n",
    "- theorem: the \"furthest-in-future\" algorithm is optimal (minimizes the number of cache misses)\n",
    "- serves as guideline for practical algorithm (\"Least Recently Used\" should do well provided data exhibits locality of reference)\n",
    "- serves as idealized benchmark for caching algorithms\n",
    "\n",
    "## Application - scheduling\n",
    "\n",
    "- setup\n",
    "    - one shared resource(ex. a processor)\n",
    "    - many \"jobs\" to do (ex. processes)\n",
    "- question\n",
    "    - in what order should we sequence the jobs?\n",
    "- assume: each job has a \n",
    "    - weight $w_{j}$ (\"priority\")\n",
    "    - length $l_{j}$\n",
    "- definition: the completion time $c_{j}$ of job $j$ = sum of job lengths up to and including $j$\n",
    "- goal: minimizes the weighted sum of completion times $min \\displaystyle\\sum_{j=1}^{n}w_{j}c_{j}$\n",
    "- intuition\n",
    "    - with equal lengths, schedule larger or smaller weight jobs earlier? larger\n",
    "    - with equal weights, schedule shorter or longer jobs earlier? shorter\n",
    "- what if $w_{i} \\gt w_{j}$ but $l_{i} \\gt l_{j}$?\n",
    "    - assign \"scores\" to jobs that are\n",
    "        - increasing in weight\n",
    "        - decreasing in length\n",
    "- guess #1: order jobs by decreasing value of $w_{j} - l_{j}$ (not always correct)\n",
    "- guess #2: order jobs by decreasing raio $\\dfrac{w_{j}}{l_{j}}$ (always correct, runs in $O(nlogn)$ - just need to sort)\n",
    "\n",
    "### claim - guess #2 is alway correct\n",
    "\n",
    "- by an exchange argument\n",
    "- fix arbitrary input of $n$ jobs\n",
    "- consider proof by contradiction\n",
    "- let $\\sigma$ = greedy schedule, $\\sigma*$ = optimal schedule (with $\\sigma*$ better than $\\sigma$)\n",
    "- assume all $\\dfrac{w_{j}}{l_{j}}$'s are distinct\n",
    "- assume by just renaming jobs $\\dfrac{w_{1}}{l_{1}} \\gt \\dfrac{w_{2}}{l_{2}} \\gt \\dots \\gt \\dfrac{w_{n}}{l_{n}}$\n",
    "- thus, greedy schedule $\\sigma$ is just $1,2,3 \\dots n$\n",
    "- thus, if optimal schedule $\\sigma^{*} \\ne \\sigma$, then there are consecutive jobs $i,j$ with $i>j$\n",
    "- suppose we exchange order of $i,j$ in $\\sigma^{*}$ (leaving other jobs unchanged)\n",
    "    - cost of exchange is $w_{i}l_{j}$ ($c_{i}$ goes up by $l_{j}$)\n",
    "    - benefit of exchange is $w_{j}l_{i}$ ($c_{j}$ goes down by $l_{i}$)\n",
    "    - $i \\gt j => \\dfrac{w_{i}}{l_{i}} \\lt \\dfrac{w_{j}}{l_{j}} => \\dfrac{w_{i}}{l_{j}} \\lt \\dfrac{w_{j}}{l_{i}}$\n",
    "        - cost $\\lt$ benefit, meaning swap improves $\\sigma^{*}$, contradicts optimality of $\\sigma^{*}$ \n",
    "        \n",
    "### claim - guess #2 is correct even with ties\n",
    "\n",
    "- fix arbitrary input of $n$ jobs\n",
    "- let $\\sigma$ = greedy schedule, $\\sigma^{*}$ = any other schedule\n",
    "- will show $\\sigma$ at least as good as $\\sigma^{*}$\n",
    "    - implies that greedy schedule is optimal\n",
    "- assume by just renaming jobs, greedy schedule $\\sigma$ is just $1,2,3 \\dots n$ (and so $\\dfrac{w_{1}}{l_{1}} \\gt \\dfrac{w_{2}}{l_{2}} \\gt \\dots \\gt \\dfrac{w_{n}}{l_{n}}$)\n",
    "- consider arbitrary schedule $\\sigma*$. If $\\sigma^{*} = \\sigma$, done\n",
    "- else recall there exists consecutive jobs $i,j$ in $\\sigma^{*}$ with $i \\gt j$\n",
    "- exchanging $i$ and $j$ in $\\sigma^{*}$ has net benefit of $w_{j}l_{i}-w_{i}l_{j} \\ge 0$\n",
    "- exchanging an \"adjacent inversion\" like $i,j$ only makes $\\sigma^{*}$ better, and it decreases the number of inverted pairs (jobs $i,j$ with $i \\gt j$ and $i$ scheduled earlier)\n",
    "- after at most $n\\choose{2}$ such exchanges, can transform $\\sigma^{*}$ into $\\sigma$\n",
    "- $\\sigma$ at least as good as $\\sigma^{*}$\n",
    "- greedy is optimal\n",
    "\n",
    "## Minimum spanning trees\n",
    "\n",
    "- input: \"undirected\" graph\" $G=(V,E)$ and a cost (for each edge $e \\in E$)\n",
    "    - assume adjacency list representation \n",
    "    - OK if edge cost are negative\n",
    "- output: minimum cost tree $T \\subseteq E$ that spans all vertices \n",
    "    - $T$ has no cycles\n",
    "    - subgraph $(U,T)$ is connected\n",
    "- assumption #1: input graph $G$ is connected\n",
    "    - else no spanning trees\n",
    "    - easy to check in preprocessing (ex. depth-first search)\n",
    "- assumption #2: edge costs are distinct\n",
    "    - Prim + Kruskal remain correct with ties (which can be broken arbitrarily)\n",
    "    \n",
    "## Prim's MST algorithm\n",
    "\n",
    "- runs in $O(mn)$\n",
    "- initialize $X = \\{s\\}$ # $s \\in V$ chosen arbitrary\n",
    "- T = empty set # invariant: $X$ = vertices spanned by tree-so-far $T$\n",
    "- while $X \\ne V$ # increases the number of spanned vertices in cheapest way possible\n",
    "    - let edge$(u,v)$ be the cheapest edge with $u \\in X$ and $v \\notin X$\n",
    "    - add $e$ to $T$\n",
    "    - add $v$ to $X$\n",
    "    \n",
    "### claim - Prim's algorithm outputs a spanning tree\n",
    "\n",
    "- definition: a cut of a graph $G = (V,E)$ is a partition of $V$ into 2 non-empty sets\n",
    "- empty cut lemma\n",
    "    - a graph is not connected <=> there exists a cut$(A,B)$ with no crossing edges\n",
    "    - proof: (<=)\n",
    "        - assume RHS\n",
    "        - pick any $u \\in A$ and $v \\in B$\n",
    "        - since no edges cross $(A,B)$, there is no $u,v$ path in $G$ \n",
    "        - thus, $G$ not connected\n",
    "    - proof: (=>)\n",
    "        - suppose $G$ has no $u,v$ path\n",
    "        - define $A$ = {vertices reachable from $u$ in $G$} ($u$'s connected component)\n",
    "        - define $B$ = {all other vertices} (all other connected components)\n",
    "        - note: no edges cross out $(A,B)$ (otherwise $A$ would be bigger!)\n",
    "- double-crossing lemma\n",
    "    - suppose the cycle $C \\subseteq E$ has an edge crossign the cut$(A,B)$, then so does some other edge of $C$\n",
    "- lonely cut corollary\n",
    "    - if $e$ is the only edge crossing some cut$(A,B)$, then it is not in any cycle (if it were in a cycle, some other edge would have to cross the cut!)\n",
    "- in summary\n",
    "    - (1) algorithm maintains invariant that $T$ spans $X$\n",
    "    - (2) can't get stuck with $X \\ne V$ (otherwise the cut $(X, V-X)$ must be empty - by empty cut lemma, input graph $G$ is disconnected)\n",
    "    - (3) no cycles ever get created in $T$\n",
    "        - consider any iteration with current sets $X$ and $T$\n",
    "        - suppose $e$ gets added\n",
    "        - $e$ is the first edge crossing $(X, V-X)$ that gets added to $T$ => its addition can't create a cycle in $T$ (by lonely cut corollary)\n",
    "        \n",
    "### claim - Prim's algorithm always outputs a minimum-cost spanning tree\n",
    "\n",
    "- cut property: consider an edge $e$ of $G$. suppose there is a cut $(A,B)$ such that $e$ is the cheapest edge of $G$ that crosses it. then $e$ belongs to the MST of $G$\n",
    "- claim: cut property => Prim's algorithm is correct\n",
    "    - already proved Prim's algorithm outputs a spanning tree $T^{*}$\n",
    "    - key point: every edge $e \\in T^{*}$ is explicitly justified by the cut property\n",
    "        - $T^{*}$ is a subset of the MST\n",
    "        - since $T^{*}$ is already a spanning tree, it must be the MST\n",
    "- proof of cut property\n",
    "    - suppose there is an edge $e$ that is the cheapest one crossing a cut$(A,B)$, yet $e$ is not in the MST $T^{*}$\n",
    "    - idea: exchange $e$ with another edge in $T^{*}$ to make it even cheaper (contradiction)\n",
    "    - since $T^{*}$ is connected, must construct an edge $f (\\ne e)$ crossing $(A,B)$\n",
    "    - idea: exchange $e$ and $f$ to get a spanning tree cheaper than $T^{*}$ (contradiction)\n",
    "    - let $C$ = cycle created by adding $e$ to $T^{*}$\n",
    "    - by double-crossing lemma: some other edge $e^{'}$ of $C$ (with $e^{'} \\ne e$ and $e^{'} \\in T^{*}$) crosses $(A,B)$ \n",
    "    - note: $T = T^{*}\\cup\\{e\\}-\\{e^{'}\\}$ is also a spanning tree\n",
    "    - since $C_{e} \\lt C_{e^{'}}$, $T$ is cheaper than purported MST $T^{*}$, contradiction!\n",
    "    \n",
    "## Prim's algorithm with heaps\n",
    "\n",
    "- invariant #1: elements in heap = vertices of $V-X$\n",
    "- invariant #2: for $v \\in V-X$, $key[v]$ = cheapest edge $(u,v)$ with $i \\in X$ (or $+\\infty$ if no such edges exist)\n",
    "- check: can initialize heap with $O(m+nlogn) = O(mlogn)$ preprocessing\n",
    "- note: given invariants, extract-min yields next vertex $v \\notin X$ and edge $(u,v)$ crossing $(X, V-X)$ to add to $X$ and $T$, respectively\n",
    "- issue: might need to recognize some keys to maintain invariant #2 after each extract-min\n",
    "\n",
    "When $v$ added to $X$\n",
    "- for each edge $(v,w) \\in E$\n",
    "    - if $w \\in V-X$\n",
    "        - (update key if needed)\n",
    "        - delete $w$ from heap\n",
    "        - recompute $key[w] = min[key[w], c_{vw}]$\n",
    "        - re-insert into heap\n",
    "        \n",
    "Running time with heaps\n",
    "- dominated by time required for heap operations\n",
    "- $(n-1)$ inserts during preprocessing\n",
    "- $(n-1)$ extract-mins (one per iteration of while loop)\n",
    "- each edge $(v,w)$ triggers one delete/insert combo (when its first endpoint is sucked into $X$)\n",
    "- $O(m)$ heap operations (recall $m \\ge n-1$ since $G$ connected)\n",
    "- $O(mlogn)$ time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "    \n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "    \n",
    "    Returns:\n",
    "    (data_array, num_nodes) -- a tuple with an array representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "    \n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0]) \n",
    "        del array_of_array[0] # delete first element, which is just the length of data\n",
    "        for array in array_of_array:\n",
    "            subarray = array.split(\" \")\n",
    "            node1 = int(subarray[0])\n",
    "            node2 = int(subarray[1])\n",
    "            cost = int(subarray[2])\n",
    "            data_array.append((node1, node2, cost))\n",
    "    return (data_array, num_nodes)\n",
    "\n",
    "\n",
    "def greedy_search(array, X, T):\n",
    "    \"\"\"\n",
    "    For all node1 in X, find node2 that is not in X, that makes the cheapest edge between node1 and node2\n",
    "    \n",
    "    Args:\n",
    "    array -- a list of tuples representing a graph\n",
    "    X -- a list to store all vertices that consist minimun spanning tree\n",
    "    T -- a list to store all costs of edges that consist minimun spanning tree\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    minimum_cost = 1000000\n",
    "    minimum_node1 = 0\n",
    "    minimum_node2 = 0\n",
    "    for node1 in X:\n",
    "        for node2 in get_connected_node(node1, array):\n",
    "            if node2 not in X:\n",
    "                cost = get_cost(node1, node2, array)\n",
    "                if cost < minimum_cost:\n",
    "                    minimum_node1 = node1\n",
    "                    minimum_node2 = node2\n",
    "                    minimum_cost = cost\n",
    "    \n",
    "    X.append(minimum_node2)\n",
    "    T.append(minimum_cost)\n",
    "    \n",
    "    \n",
    "def get_connected_node(node1, array):\n",
    "    \"\"\"\n",
    "    Find all nodes that are connected by an edge for node1\n",
    "    \n",
    "    Args:\n",
    "    node1 -- input node\n",
    "    array -- a list of tuples representing a graph\n",
    "    \"\"\"\n",
    "    \n",
    "    nodes = []\n",
    "    \n",
    "    for item in array:\n",
    "        if item[0] == node1:\n",
    "            nodes.append(item[1])\n",
    "        elif item[1] == node1:\n",
    "            nodes.append(item[0])\n",
    "            \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_cost(node1, node2, array):\n",
    "    \"\"\"\n",
    "    Find cost of edge between node1 and node2\n",
    "    \n",
    "    Args:\n",
    "    node1 -- first node of an edge\n",
    "    node2 -- second node of an edge\n",
    "    array -- a list of tuples representing a graph\n",
    "    \n",
    "    Returns:\n",
    "    cost -- cost of edge between node1 and node2\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = 0\n",
    "    \n",
    "    for item in array:\n",
    "        if item[0] == node1 and item[1] == node2:\n",
    "            cost = item[2]\n",
    "        if item[0] == node2 and item[1] == node1:\n",
    "            cost = item[2]\n",
    "            \n",
    "    return cost\n",
    "            \n",
    "    \n",
    "tuple_obj = open_file(\"data/edge.txt\")\n",
    "# tuple_obj = open_file(\"data/edge-test1.txt\") #7\n",
    "# tuple_obj = open_file(\"data/edge-test2.txt\") #15\n",
    "# tuple_obj = open_file(\"data/edge-test3.txt\") #14\n",
    "array = tuple_obj[0]\n",
    "num_nodes = tuple_obj[1]\n",
    "s = array[0][0] # pick random node\n",
    "X = [] # store explored nodes\n",
    "X.append(s)\n",
    "T = [] # store costs\n",
    "T.append(0)\n",
    "\n",
    "while len(X) < num_nodes:\n",
    "    greedy_search(array, X, T)\n",
    "    \n",
    "print(sum(T))\n",
    "# -3612829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal's MST Algorithm\n",
    "\n",
    "- sort edges in order of increasing cost (rename edges 1,2,3,... so that $c_{1} < c_{2} < \\dots < c_{m}$)\n",
    "- let T = empty set\n",
    "- for i=1 to m\n",
    "    - if T + {i} has no cycles\n",
    "        - add i to T\n",
    "- return T\n",
    "\n",
    "Union-Find\n",
    "- $Union(C_{i}, C_{j}$): fuse graph $C_{i}, C_{j}$ into a single one\n",
    "- maintain one linked structure\n",
    "- each vertex points to the leader of its component (none of a component inherited from leader vertex)\n",
    "- given edge(u,v), can check if u and v are already in some component in $O(1)$ time (iff leader pointers of u and v match <=> Find(u) = Find(v)\n",
    "- when new edge(u,v) added to T, connected components of u and v merge\n",
    "- when two components merge, have smaller one inherit the leader of the larger one\n",
    "\n",
    "Clustering\n",
    "- given n points, classify into coherent groups\n",
    "- initially, each point in a separate cluster\n",
    "- repeat until only k clusters\n",
    "    - let p,q = closest paif of separate points\n",
    "    - merge the cluster containing p and q into a single cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    (data_array, num_nodes) -- a tuple with an array representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0])\n",
    "        del array_of_array[0] # delete first element, which is just the length of data\n",
    "        for array in array_of_array:\n",
    "            subarray = array.split(\" \")\n",
    "            node1 = int(subarray[0])\n",
    "            node2 = int(subarray[1])\n",
    "            cost = int(subarray[2])\n",
    "            data_array.append((node1, node2, cost))\n",
    "    return (data_array, num_nodes)\n",
    "\n",
    "\n",
    "def find_closest_pair_and_merge(sorted_array, T):\n",
    "    \"\"\"\n",
    "    Find two nodes that are in different clusters, and merge them into a single cluster\n",
    "\n",
    "    Args:\n",
    "    sorted_array -- a list of tuple what is sorted by its thrid element (that is cost between two nodes)\n",
    "    T -- a list of list that contains \"clusers\"\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    node1 = sorted_array[0][0]\n",
    "    node2 = sorted_array[0][1]\n",
    "    cost = sorted_array[0][2]\n",
    "\n",
    "    index_of_cluster_to_expand = find_cluster(node1, T)\n",
    "    index_of_cluster_to_remove = find_cluster(node2, T)\n",
    "\n",
    "    print(str(node1) + \" and \" + str(node2) + \": \" + str(index_of_cluster_to_expand) + \" => \" + str(index_of_cluster_to_remove))\n",
    "\n",
    "    if index_of_cluster_to_expand != index_of_cluster_to_remove: # if two nodes are already in the same cluster, no need to perform merge on T\n",
    "        for node in T[index_of_cluster_to_remove]:\n",
    "            T[index_of_cluster_to_expand].append(node) # add all nodes in the cluster where node2 belongs to node1's cluster\n",
    "        del T[index_of_cluster_to_remove] # remove node2's cluster\n",
    "        del sorted_array[0] # remove current tuple\n",
    "    else:\n",
    "        del sorted_array[0] # remove current tuple\n",
    "\n",
    "\n",
    "def find_cluster(node, T):\n",
    "    \"\"\"\n",
    "    Find a list inside T where node belongs\n",
    "\n",
    "    Args:\n",
    "    node -- an integer representing a node in a graph\n",
    "    T -- a list of list that contains \"clusers\"\n",
    "\n",
    "    Returns:\n",
    "    i -- index of cluster of T\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(T)):\n",
    "        if node in T[i]:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_max_spacing(T, sorted_array):\n",
    "    \"\"\"\n",
    "    Return the minimum distance of two nodes that are in different clusters\n",
    "\n",
    "    Args:\n",
    "    sorted_array -- a list of tuple what is sorted by its thrid element (that is cost between two nodes)\n",
    "    T -- a list of list that contains \"clusers\"\n",
    "\n",
    "    Returns:\n",
    "    item[2] -- the minimum cost\n",
    "    \"\"\"\n",
    "\n",
    "    for item in sorted_array:\n",
    "        cluster_of_node1 = find_cluster(item[0], T)\n",
    "        cluster_of_node2 = find_cluster(item[1], T)\n",
    "        if cluster_of_node1 != cluster_of_node2:\n",
    "            return item[2]\n",
    "\n",
    "\n",
    "tuple_obj = open_file(\"data/clustering.txt\")\n",
    "# tuple_obj = open_file(\"data/clustering-test1.txt\")\n",
    "array = tuple_obj[0]\n",
    "sorted_array = sorted(array, key=lambda x: (x[2])) # sort by third element\n",
    "num_nodes = tuple_obj[1]\n",
    "print(\"len(array):\" + str(len(sorted_array)))\n",
    "\n",
    "\n",
    "T = []\n",
    "for node in range(1, num_nodes+1):\n",
    "    T.append([node])\n",
    "print(\"len(T): \" + str(len(T)))\n",
    "print(T)\n",
    "\n",
    "while len(T) > 4 and len(sorted_array) > 0:\n",
    "    find_closest_pair_and_merge(sorted_array, T)\n",
    "\n",
    "print(get_max_spacing(T, sorted_array))\n",
    "\n",
    "# Max-spacing:100, two clusters: Nodes(1,2) Nodes(3,4,5)\n",
    "# Max-spacing:105, four clusters\n",
    "# Max-spacing:106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils.union_find import UnionFind\n",
    "\n",
    "\n",
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows with weight and length, and compute difference and ratio\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    data_array -- an array of tuplesrepresenting a graph\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    data_array = []\n",
    "    num_nodes = 0\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        array_of_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(array_of_array[0].split(\" \")[0])\n",
    "        num_bits = int(array_of_array[0].split(\" \")[1])\n",
    "        del array_of_array[0] # delete first element, which is just metadata\n",
    "        for i in range(0, len(array_of_array)):\n",
    "            number = int(array_of_array[i].replace(\" \", \"\"))\n",
    "            data_array.append(number)\n",
    "            if number not in data_dict:\n",
    "                data_dict[number] = set()\n",
    "            data_dict[number].add(i+1)\n",
    "                  \n",
    "    return (data_array, data_dict, num_nodes, num_bits)\n",
    "\n",
    "\n",
    "def convert_base_10_to_2(array):\n",
    "    \"\"\"\n",
    "    Convert a list of integers (base 10) to a list of integers (base 2)\n",
    "    \n",
    "    Args:\n",
    "    array - list of integers\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for i in range(0, len(array)):\n",
    "        array[i] = int(bin(array[i])[2:])\n",
    "    \n",
    "    \n",
    "tuple_obj = open_file(\"data/clustering-big.txt\")\n",
    "# tuple_obj = open_file(\"data/clustering-big-test1.txt\")\n",
    "# tuple_obj = open_file(\"data/clustering-big-test2.txt\")\n",
    "data_array = tuple_obj[0]\n",
    "data_dict = tuple_obj[1]\n",
    "num_nodes = tuple_obj[2]\n",
    "num_bits = tuple_obj[3]\n",
    "print(\"len(data_array): \" + str(len(data_array)))\n",
    "print(\"len(data_dict): \" + str(len(data_dict)))\n",
    "print(\"num_nodes: \" + str(num_nodes))\n",
    "print(\"num_bits: \" + str(num_bits))\n",
    "\n",
    "unionFind = UnionFind()\n",
    "\n",
    "# Hemming distance of 1\n",
    "heming_distance_1 = [1 << i for i in range(num_bits)]\n",
    "\n",
    "convert_base_10_to_2(heming_distance_1)\n",
    "print(len(heming_distance_1)) #24\n",
    "\n",
    "# Hemming distance of 2\n",
    "heming_distance_2 = []\n",
    "for i in range(0, len(heming_distance_1)):\n",
    "    for j in range(0, len(heming_distance_1)):\n",
    "        if j > i:\n",
    "            dist = int(str(heming_distance_1[i]),2) ^ int(str(heming_distance_1[j]),2)\n",
    "            heming_distance_2.append(dist)\n",
    "        \n",
    "convert_base_10_to_2(heming_distance_2)\n",
    "print(len(heming_distance_2)) # 276\n",
    "\n",
    "distances = heming_distance_1 + heming_distance_2\n",
    "print(len(distances))\n",
    "\n",
    "for distance in distances:\n",
    "    for key1 in data_dict:\n",
    "        key2 = int(str(distance),2) ^ int(str(key1),2)\n",
    "        key2 = int(bin(key2)[2:]) \n",
    "        if key2 in data_dict:\n",
    "            unionFind.union(key1, key2)\n",
    "\n",
    "pointer_set = set([unionFind[x] for x in data_dict])\n",
    "num_clusters = len(pointer_set)\n",
    "print(num_clusters)\n",
    "\n",
    "# 3\n",
    "# 15\n",
    "# 6118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman Codes\n",
    "\n",
    "Binary code: maps alphabet to binary string. For example, {A, B, C, D} => {00, 01, 10, 11}\n",
    "How about use instead \"prefix-free\" such that {A, B, C, D} => {0, 10, 110, 111}\n",
    "\n",
    "In general\n",
    "- left child edges get \"0\"\n",
    "- right child edges get \"1\"\n",
    "- for each $i$, there is exactly one node labelled $i$\n",
    "- encoding: bits along path from root to node $i$\n",
    "- decoding: repeatedly follow path from root until hitting a leaf\n",
    "- encoding length of $i$ = depth of $i$ in a tree\n",
    "\n",
    "Given probability $p_{i}$ for each character $i$, find Tree $T$ that minimize the length of encoding defined by\n",
    "\n",
    "$L(T) = \\displaystyle\\sum_{i}P_{i}$(depth of $i$ in T)\n",
    "\n",
    "Idea: build the tree bottom up using successive merges\n",
    "- if len(set) = 2, return\n",
    "- let $a$,$b$ have the smallest frequencies\n",
    "- let new_set = set with $a$ & $b$ replaced by $ab$\n",
    "- define $p_{ab} = p_{a} + p_{b}$ \n",
    "- recursively comput $T^{'}$ (for new_set)\n",
    "- extend $T^{'}$ to $T$ by splitting leaf $ab$ into two leave $a$ & $b$\n",
    "- return $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "\n",
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    (data_dict, num_nodes) -- a tuple with a dictionary representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    num_nodes = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(data_array[0].split(\" \")[0])\n",
    "        del data_array[0] # delete first element, which is just the length of data\n",
    "        for item in data_array:\n",
    "            data_dict[str(index)] = int(item)\n",
    "            index += 1\n",
    "    return (data_dict, num_nodes)\n",
    "\n",
    "\n",
    "tuple_obj = open_file(\"data/huffman.txt\")\n",
    "# tuple_obj = open_file(\"data/huffman-test1.txt\")\n",
    "data_dict = tuple_obj[0]\n",
    "num_nodes = tuple_obj[1]\n",
    "\n",
    "sorted_dict_by_value = {k: v for k, v in sorted(data_dict.items(), key=lambda item: item[1])}\n",
    "tree_merge_track = []\n",
    "\n",
    "while len(sorted_dict_by_value) > 2:\n",
    "    first_two_items = dict(itertools.islice(sorted_dict_by_value.items(), 2)) # get two smallest values\n",
    "    first_node = \"\"\n",
    "    second_node = \"\"\n",
    "    new_weight = 0\n",
    "    for key, value in first_two_items.items():\n",
    "        if first_node == \"\":\n",
    "            first_node = key\n",
    "        else:\n",
    "            second_node = key\n",
    "        new_weight += value\n",
    "        del sorted_dict_by_value[key] # delete two smallest nodes\n",
    "        \n",
    "    new_node = first_node + \" \" + second_node \n",
    "    tree_merge_track.append(new_node) \n",
    "    sorted_dict_by_value[new_node] = new_weight # create a new node that is a combination of the two smallest nodes\n",
    "    sorted_dict_by_value = {k: v for k, v in sorted(sorted_dict_by_value.items(), key=lambda item: item[1])}\n",
    "    \n",
    "# print(sorted_dict_by_value)\n",
    "\n",
    "# Find \"occurance\" of each node in merge operation\n",
    "count_dict = {}\n",
    "for item in tree_merge_track:\n",
    "    for char in item.split(\" \"):\n",
    "        if char not in count_dict:\n",
    "            count_dict[char] = 1\n",
    "        count_dict[char] += 1\n",
    "        \n",
    "print(len(count_dict))\n",
    "print(count_dict)\n",
    "sorted_count_dict_by_value = {k: v for k, v in sorted(count_dict.items(), key=lambda item: item[1])}\n",
    "# Max: 19, Min: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming\n",
    "\n",
    "Ex. Graph G = (V,E) with non-negative weights on vertices. Compute subset of non-adjacent vertices that constitute the maximum total weight\n",
    "\n",
    "Let $S$ (in $V$) be a max-weight independent set\n",
    "- suppose $v_{n}$ not in $S$\n",
    "- let $G^{'}$ = $G$ with $v_{n}$ deleted\n",
    "- S is also an independent set of $G^{'}$\n",
    "- S must be a max-weight independent set of $G^{'}$\n",
    "\n",
    "This time\n",
    "- suppose $v_{n}$ in $S$\n",
    "- then, previous vertex $v_{n-1}$ not in $S$\n",
    "- let $G^{''}$ = $G$ with $v_{n}$ and $v_{n-1}$ deleted\n",
    "- S-{$v_{n}$} is also an independent set of $G^{'}$\n",
    "- S-{$v_{n}$} must be a max-weight independent set of $G^{''}$\n",
    "\n",
    "Thus, max-weight independent set must be either\n",
    "- max-weight independent set of $G^{'}$ or\n",
    "- $v_{n}$ + max-weight independent set of $G^{''}$\n",
    "\n",
    "Algorithm\n",
    "- let $G_{i}$ = 1st $i$ vertices of $G$\n",
    "- populate array $A$ left to right with $A[i]$ = value of max-weight independent set of $G_{i}$\n",
    "- init: $A[0] = 0$ and $A[1] = w_{1}$\n",
    "- main loop: for $i = 2,3,4 \\dots n$, $A[i] = max[A[i-1], A[i-2]+w_{i}]$\n",
    "\n",
    "Then trace back through filled-in array to reconstruct optimal solution\n",
    "- let $A$ = filled-in array\n",
    "- let $S$ = empty set\n",
    "- while $i \\ge 1$ \n",
    "    - if $A[i-1] \\ge A[i-2] + w_{i}$\n",
    "        - decrease i by 1\n",
    "    - else\n",
    "        - add $v_{i}$ to $S$ \n",
    "        - decrease $i$ by 2\n",
    "- return $S$\n",
    "\n",
    "### Principle of Dynamic Programming\n",
    "1. Identify a small number of sub-problems\n",
    "2. Given solutions to smaller sub-problems, can solve larger sub-problems\n",
    "3. Solving all sub-problems computes final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    (data_dict, num_nodes) -- a tuple with a dictionary representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    num_nodes = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        num_nodes = int(data_array[0].split(\" \")[0])\n",
    "        del data_array[0] # delete first element, which is just the length of data\n",
    "        for item in data_array:\n",
    "            data_dict[index] = int(item)\n",
    "            index += 1\n",
    "    return (data_dict, num_nodes)\n",
    "\n",
    "\n",
    "tuple_obj = open_file(\"data/max-weight-independent-set.txt\")\n",
    "# tuple_obj = open_file(\"data/max-weight-independent-set-test1.txt\")\n",
    "# tuple_obj = open_file(\"data/max-weight-independent-set-test2.txt\")\n",
    "data_dict = tuple_obj[0]\n",
    "num_nodes = tuple_obj[1]\n",
    "\n",
    "A = {}\n",
    "A[0] = 0\n",
    "A[1] = data_dict[1]\n",
    "for i in range(2, num_nodes + 1):\n",
    "    A[i] = max(A[i-1], A[i-2] + data_dict[i])\n",
    "\n",
    "S = set()\n",
    "while num_nodes > 1:\n",
    "    if A[num_nodes-1] >= A[num_nodes-2] + data_dict[num_nodes]:\n",
    "        num_nodes -= 1\n",
    "    else:\n",
    "        S.add(num_nodes)\n",
    "        num_nodes -= 2\n",
    "if 2 not in S:\n",
    "    S.add(1)\n",
    "\n",
    "ret = \"\"\n",
    "for i in [1, 2, 3, 4, 17, 117, 517, 997]:\n",
    "    if i in S:\n",
    "        ret += \"1\"\n",
    "    else:\n",
    "        ret += \"0\"\n",
    "print(ret)\n",
    "# 10100110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knapsack Problem\n",
    "\n",
    "Ex. n items\n",
    "- value $v_{i}$ (non-negative)\n",
    "- size $w_{i}$ (non-negative and integral)\n",
    "- capacity $W$ (non-negative integer)\n",
    "\n",
    "Find subset $S$ in ${1 \\dots n}$ that maximizes $\\displaystyle\\sum_{i}v_{i}$ subject to $\\displaystyle\\sum_{i}w_{i} \\le W$\n",
    "\n",
    "Let S = a max-value solution\n",
    "- suppose item n not in $S$. Then $S$ must be optimal with first $n-1$ items with capacity $W$\n",
    "- suppose item n in $S$. Then $S-\\{n\\}$ must be optimal with first $n-1$ items with capacity $W-w_{n}$\n",
    "\n",
    "Let $v_{i,x}$ = value of the best solution that\n",
    "- uses only the first $i$ items\n",
    "- has total size $\\le x$\n",
    "\n",
    "Then,\n",
    "- for i = 1 to n and any x\n",
    "    - $v_{i,x}$ = max{$v_{i-1,x}$ (case when item $i$ in excluded), $v_{i} + v_{i-1,x-w_{i}}$ (case when item $i$ in included)}\n",
    "- if $w_{i} > x$, then $v_{i,x} = v_{i-1,x}$\n",
    "\n",
    "Pseudo code\n",
    "- let A = 2-D array\n",
    "- init $A[0,x] = 0$ for $x = 0 \\dots W$\n",
    "- for i = 1 to n\n",
    "    - for $x = 0 \\dots W$\n",
    "        - $A[i,x] = max\\{A[i-1, x], A[i-1, x-w_{i}] + v_{i}\\}$\n",
    "- return $A[n,W]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    (data_dict, num_nodes) -- a tuple with a dictionary representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    knapsack_size = 0\n",
    "    num_items = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        knapsack_size = int(data_array[0].split(\" \")[0])\n",
    "        num_items = int(data_array[0].split(\" \")[1])\n",
    "        del data_array[0] # delete first element, which is just metadata\n",
    "        for item in data_array:\n",
    "            value = int(item.split(\" \")[0])\n",
    "            weight = int(item.split(\" \")[1])\n",
    "            data_dict[index] = (value, weight)\n",
    "            index += 1\n",
    "    return (data_dict, knapsack_size, num_items)\n",
    "\n",
    "\n",
    "# tuple_obj = open_file(\"data/knapsack-test1.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack-test2.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack-test3.txt\")\n",
    "tuple_obj = open_file(\"data/knapsack-test4.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack.txt\")\n",
    "data_dict = tuple_obj[0]\n",
    "knapsack_size = tuple_obj[1]\n",
    "num_items = tuple_obj[2]\n",
    "print(data_dict)\n",
    "print(knapsack_size)\n",
    "print(num_items)\n",
    "\n",
    "A = []\n",
    "for i in range(0, num_items + 1):\n",
    "    A.append([])\n",
    "    for j in range(0, knapsack_size + 1):\n",
    "        A[i].append(0)\n",
    "    \n",
    "    \n",
    "for i in range(1, num_items + 1):\n",
    "    for j in range(0, knapsack_size + 1):\n",
    "#         print(str(A[i-1][j]) +\" vs \"+ str(A[i-1][j-data_dict[i][1]]) + \" + \" + str(data_dict[i][0]))\n",
    "        if data_dict[i][1] > j:\n",
    "            A[i][j] = A[i-1][j]\n",
    "        else:\n",
    "            A[i][j] = max(A[i-1][j], A[i-1][j-data_dict[i][1]] + data_dict[i][0])\n",
    "        \n",
    "print(A[num_items][knapsack_size])\n",
    "\n",
    "# 14\n",
    "# 150\n",
    "# 147\n",
    "# 8\n",
    "# 2493893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    Read-in a file containing rows of data\n",
    "\n",
    "    Args:\n",
    "    file_path -- location of file to read\n",
    "\n",
    "    Returns:\n",
    "    (data_dict, num_nodes) -- a tuple with a dictionary representing a graph and an integer reprsenting number of nodes\n",
    "    \"\"\"\n",
    "\n",
    "    data_dict = {}\n",
    "    knapsack_size = 0\n",
    "    num_items = 0\n",
    "    index = 1\n",
    "\n",
    "    with open(file_path, 'r') as line:\n",
    "        data_array = line.read().split(\"\\n\")\n",
    "        knapsack_size = int(data_array[0].split(\" \")[0])\n",
    "        num_items = int(data_array[0].split(\" \")[1])\n",
    "        del data_array[0] # delete first element, which is just metadata\n",
    "        for item in data_array:\n",
    "            value = int(item.split(\" \")[0])\n",
    "            weight = int(item.split(\" \")[1])\n",
    "            data_dict[index] = (value, weight)\n",
    "            index += 1\n",
    "    return (data_dict, knapsack_size, num_items)\n",
    "\n",
    "\n",
    "# tuple_obj = open_file(\"data/knapsack-test1.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack-test2.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack-test3.txt\")\n",
    "# tuple_obj = open_file(\"data/knapsack-test4.txt\")\n",
    "tuple_obj = open_file(\"data/knapsack-big.txt\")\n",
    "data_dict = tuple_obj[0]\n",
    "knapsack_size = tuple_obj[1]\n",
    "num_items = tuple_obj[2]\n",
    "# print(data_dict)\n",
    "# print(knapsack_size)\n",
    "# print(num_items)\n",
    "\n",
    "A = []\n",
    "for i in range(0, 2):\n",
    "    A.append([]) \n",
    "    for j in range(0, knapsack_size + 1):\n",
    "        A[i].append(0)\n",
    "    \n",
    "i = 1\n",
    "while i <= num_items:\n",
    "    A[1][0:data_dict[i][1]] = A[0][0:data_dict[i][1]][:]\n",
    "    for j in range(data_dict[i][1], knapsack_size + 1):\n",
    "        if data_dict[i][1] > j:\n",
    "            A[1][j] = A[0][j]\n",
    "        else:\n",
    "#             print(str(A[0][j]) +\" vs \"+ str(A[0][j-data_dict[i][1]]) + \" + \" + str(data_dict[i][0]))\n",
    "            A[1][j] = max(A[0][j], A[0][j-data_dict[i][1]] + data_dict[i][0])\n",
    "    A[0] = A[1][:] # copy array by value, not reference\n",
    "    print(str(i) + \" -> \" + str(A[1][knapsack_size]))\n",
    "    i += 1\n",
    "     \n",
    "# 14\n",
    "# 150\n",
    "# 147\n",
    "# 8\n",
    "# 4243395"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Alignment\n",
    "\n",
    "- strings $X = x_{1} \\dots x_{m}$, $Y = y_{1} \\dots y_{m}$\n",
    "- penalty $\\alpha_{gap} \\ge 0$ for inserting a gap, $\\alpha_{ab}$ for matching $a$ and $b$\n",
    "- insert gaps to equalize length of string\n",
    "\n",
    "Final position of string can be one of\n",
    "- case1: $x_{m}$ and $y_{n}$ matched\n",
    "- case2: $x_{m}$ is matched with a gap\n",
    "- case3: $y_{n}$ is matched with a gap\n",
    "\n",
    "Let $X^{'} = X - x_{m}$ and $Y^{'} = Y - y_{m}$ \n",
    "- case1: alignment of $X^{'}$ and $Y^{'}$ is optimal\n",
    "- case2: alignment of $X^{'}$ and $Y$ is optimal\n",
    "- case3: alignment of $X$ and $Y^{'}$ is optimal\n",
    "\n",
    "Subproblem $(X_{i}m Y_{j})$\n",
    "- $X_{i}$ = 1st $i$ letters of $X$\n",
    "- $Y_{j}$ = 1st $j$ letters of $Y$\n",
    "\n",
    "Let $P_{ij}$ = penalty of optimal alignment of $X_{i}$ and $Y_{j}$\n",
    "- For all i = 1 to n and j = 1 to n, $P_{ij}$ is the **minimun** of the following three cases\n",
    "- case1: $\\alpha_{x_{i}y_{j}}$ + $P_{i-1,j-1}$\n",
    "- case2: $\\alpha_{gap}$ + $P_{i-1,j}$\n",
    "- case3: $\\alpha_{gap}$ + $P_{i,j-1}$\n",
    "\n",
    "Pseudo code\n",
    "- let A = 2-D array\n",
    "- $A[i,0] = A[0,j] = i * \\alpha_{gap}$ for all $i \\ge 0$\n",
    "- for i = 1 to m\n",
    "    - for j = 1 to n\n",
    "        - $A[i,j]$ = $min\\{A[i-1,j-1]+\\alpha_{x_{i}y_{j}}, A[i-1,j]+\\alpha_{gap}, A[i,j-1]+\\alpha_{gap}\\}$\n",
    "        \n",
    "Trace back through filled-in table $A_{i}$ starting at $A[m,n]$\n",
    "- when reaching subproblem $A[i,j]$\n",
    "    - if $A[i,j]$ filled using case1, match $x_{i}$ and $y_{j}$, and go to $A[i-1, j-1]$\n",
    "    - if $A[i,j]$ filled using case2, match $x_{i}$ and a gap, and go to $A[i-1, j]$\n",
    "    - if $A[i,j]$ filled using case3, match $y_{j}$ and a gap, and go to $A[i, j-1]$\n",
    "- if $i=0$ or $j=0$, match remaining substring with gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Binary Search Tree\n",
    "\n",
    "- what is the best search tree for a given set of keys?\n",
    "- let frequencies $p_{1} \\dots p_{n}$ for items $1 \\dots n$\n",
    "- valid search tree that minimizes weighted search time\n",
    "\n",
    "$C(T) = \\displaystyle\\sum_{i}P_{i}*$[search time for in i T]\n",
    "\n",
    "- subtrees $T_{1}$ and $T_{2}$ are optimal BSTs for the keys $\\{1 \\dots r-1\\}$ and $\\{r+1 \\dots n\\}$\n",
    "- for $1 \\ge i \\ge j \\ge n$, let $C_{ij}$ = weighted search cost of optimal BST for items $\\{i, i+1 \\dots j-1, j\\}$ with properties $\\{p_{i}, p_{i+1} \\dots p_{j}\\}$\n",
    "- for every $1 \\ge i \\ge j \\ge n$\n",
    "\n",
    "$C_{ij} = \\underset{r=i}{\\text{min}}\\left[\\displaystyle\\sum_{k=1}^{j}P_{k}+C_{i,r-1}+C_{r+1,j}\\right]$ where $C_{i,r-1}, C_{r+1,j} = 0$ if $x>y$\n",
    "\n",
    "- let A=2-D array\n",
    "- for s = 0 to n-1 (s represent j-i)\n",
    "    - for i =1 to n\n",
    "        - $A[i, i+s]$ = $\\underset{r=i}{\\text{min}}\\left[\\displaystyle\\sum_{k=i}^{i+s}P_{k}+A[i,r-1]+A[r+1,i+s]\\right]$ where $A[i,r-1]+A[r+1,i+s] = 0$ if first index $\\ge$ second index\n",
    "- return $A[1,n]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
